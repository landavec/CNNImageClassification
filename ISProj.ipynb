{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be43cea7",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5cc585",
   "metadata": {},
   "source": [
    "First and foremost, the proper libraries necessary for this project need to be imported. The libraries being used in this project are tensorflow, numpy, and matplotlib. Additionally, layer classes such as Dense, Flatten, Conv2D, and MaxPooling2D will be imported from tensorflow for neural network layer modeling purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9902b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, datasets\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf0889",
   "metadata": {},
   "source": [
    "Next, we can import and load our dataset. The dataset that will be used is the CIFAR-10 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "-The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. \n",
    "-There are 50000 training images and 10000 test images.\n",
    "-The 10 image classes are \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", & \"truck\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e9f6c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 70s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19aa33b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51796300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9885de",
   "metadata": {},
   "source": [
    "Here we can see the shape of X_train which is 50,000 images & X_test with 10,000 images that consists of 32x32 pixel dimensions along with their 3 color channels which are RGB. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c040dd7",
   "metadata": {},
   "source": [
    "Next, we will reshape our array \"y_train\" into a one dimensional array to make it simpler to apply operations and transformations to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11ef31d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0bbb7b",
   "metadata": {},
   "source": [
    "Now that we have reshaped our data, we want to add labels to each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee3dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c85d8",
   "metadata": {},
   "source": [
    "Next, we want to nromalize the pixel values to a 0-1 range. This improves the training process and makes the optimization converge faster since gradient descent is more stable when working with smaller values. Instead of working with pixel values from 0-255, we will be working with pixel values ranging from 0-1, to do this you have to divide X_train & X_test by 255. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd13dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30817632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23137255, 0.24313725, 0.24705882],\n",
       "        [0.16862745, 0.18039216, 0.17647059],\n",
       "        [0.19607843, 0.18823529, 0.16862745],\n",
       "        ...,\n",
       "        [0.61960784, 0.51764706, 0.42352941],\n",
       "        [0.59607843, 0.49019608, 0.4       ],\n",
       "        [0.58039216, 0.48627451, 0.40392157]],\n",
       "\n",
       "       [[0.0627451 , 0.07843137, 0.07843137],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.07058824, 0.03137255, 0.        ],\n",
       "        ...,\n",
       "        [0.48235294, 0.34509804, 0.21568627],\n",
       "        [0.46666667, 0.3254902 , 0.19607843],\n",
       "        [0.47843137, 0.34117647, 0.22352941]],\n",
       "\n",
       "       [[0.09803922, 0.09411765, 0.08235294],\n",
       "        [0.0627451 , 0.02745098, 0.        ],\n",
       "        [0.19215686, 0.10588235, 0.03137255],\n",
       "        ...,\n",
       "        [0.4627451 , 0.32941176, 0.19607843],\n",
       "        [0.47058824, 0.32941176, 0.19607843],\n",
       "        [0.42745098, 0.28627451, 0.16470588]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.81568627, 0.66666667, 0.37647059],\n",
       "        [0.78823529, 0.6       , 0.13333333],\n",
       "        [0.77647059, 0.63137255, 0.10196078],\n",
       "        ...,\n",
       "        [0.62745098, 0.52156863, 0.2745098 ],\n",
       "        [0.21960784, 0.12156863, 0.02745098],\n",
       "        [0.20784314, 0.13333333, 0.07843137]],\n",
       "\n",
       "       [[0.70588235, 0.54509804, 0.37647059],\n",
       "        [0.67843137, 0.48235294, 0.16470588],\n",
       "        [0.72941176, 0.56470588, 0.11764706],\n",
       "        ...,\n",
       "        [0.72156863, 0.58039216, 0.36862745],\n",
       "        [0.38039216, 0.24313725, 0.13333333],\n",
       "        [0.3254902 , 0.20784314, 0.13333333]],\n",
       "\n",
       "       [[0.69411765, 0.56470588, 0.45490196],\n",
       "        [0.65882353, 0.50588235, 0.36862745],\n",
       "        [0.70196078, 0.55686275, 0.34117647],\n",
       "        ...,\n",
       "        [0.84705882, 0.72156863, 0.54901961],\n",
       "        [0.59215686, 0.4627451 , 0.32941176],\n",
       "        [0.48235294, 0.36078431, 0.28235294]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is an example of the pixel values ranging from 0-1\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340e9ed",
   "metadata": {},
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a59aca",
   "metadata": {},
   "source": [
    "Moving on, we will get started with creating our neural network. \"Sequential()\" will be used to create an instance of a neural network model. This is a model class that represents a linear stack of layers which will allow us to define a neural network model as a sequence of layers where the data flows sequentially from the input to output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e265302",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47723b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a convolutional layer to the neural network model with 32 filters (kernels)\n",
    "#each filter is responsible for learning different features of the data\n",
    "#rectified linear unit (relu) is used as the activation function to introduce non-linearity\n",
    "#set the size of the convolutional filter to be 3x3\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape=(32, 32, 3)))\n",
    " \n",
    "#max-pooling is a downsampling operation that reduces the spatial dimensions of the feature maps produced by previous layers\n",
    "#define the size of the pooling window as 2x2\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de0a569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add another convolutional layer to the neural network model with 64 filters (kernels)\n",
    "#each filter is responsible for learning different features of the data\n",
    "#rectified linear unit (relu) is used as the activation function to introduce non-linearity\n",
    "#set the size of the convolutional filter to be 4x4\n",
    "model.add(Conv2D(filters = 64, kernel_size = (4, 4), activation = \"relu\"))\n",
    "\n",
    "#define the size of the pooling window as 2x2\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2517dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes the output of the previous layers, and converts it into a one-dimensional vector\n",
    "model.add(Flatten())\n",
    "\n",
    "#add a fully connected (dense) layer to the model\n",
    "#specify the layer has 34 units (neurons), each unit will learn different patterns from the flattened input data\n",
    "model.add(Dense(units = 34, activation = \"relu\"))\n",
    "\n",
    "#add another fully connected layer to the model\n",
    "#calculate class probabilities with softmax activation\n",
    "model.add(Dense(units = 10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2be24",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeada1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',  #specify the optimizer\n",
    "    loss='sparse_categorical_crossentropy',  #specify the loss function\n",
    "    metrics=['accuracy'])  #specify evaluation metrics \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ed450",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63270e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.1467 - accuracy: 0.9474 - val_loss: 2.2916 - val_accuracy: 0.6885\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 0.1443 - accuracy: 0.9467 - val_loss: 2.2513 - val_accuracy: 0.6876\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 0.1449 - accuracy: 0.9490 - val_loss: 2.3755 - val_accuracy: 0.6742\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1326 - accuracy: 0.9515 - val_loss: 2.5079 - val_accuracy: 0.6808\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 0.1442 - accuracy: 0.9491 - val_loss: 2.3697 - val_accuracy: 0.6853\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1302 - accuracy: 0.9541 - val_loss: 2.5269 - val_accuracy: 0.6866\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.1318 - accuracy: 0.9532 - val_loss: 2.5139 - val_accuracy: 0.6820\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.1324 - accuracy: 0.9532 - val_loss: 2.5469 - val_accuracy: 0.6861\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.1237 - accuracy: 0.9551 - val_loss: 2.5830 - val_accuracy: 0.6854\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1242 - accuracy: 0.9562 - val_loss: 2.5634 - val_accuracy: 0.6846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1694e256b80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the \"fit\" method to train the model\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10)                          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342ccc74",
   "metadata": {},
   "source": [
    "# After training the model over and over many times, we have an accuracy rate of 0.9562 or 95.62%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fab3f0",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7864e",
   "metadata": {},
   "source": [
    "Now that the model has been trained with an accuracy rate of 95%, we can start making predictions on our X_test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "961fc0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2233b7e",
   "metadata": {},
   "source": [
    "For the following example, we'll be selecting the index 7 prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca726584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7375644e-16, 8.0173183e-16, 6.5953434e-05, 3.0130113e-04,\n",
       "       2.1083551e-06, 1.1152581e-07, 9.9963057e-01, 2.9851586e-12,\n",
       "       4.8555366e-17, 2.9367747e-17], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#access prediction for index 7\n",
    "y_predictions[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1a495",
   "metadata": {},
   "source": [
    "To make the data easier to understand, we will update y_predictions to display the class indices in integers corresponding to the most likely class for each data point based on the model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bfaaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = [np.argmax(arr) for arr in y_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "267ac6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef8fa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape y_test to a one dimensial array\n",
    "y_test = y_test.reshape(-1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9e873",
   "metadata": {},
   "source": [
    "# It is important to remember that: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d23a3a",
   "metadata": {},
   "source": [
    "y_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"] \n",
    "\n",
    "\"airplane\" = 0  \n",
    "\"automobile\" = 1 \n",
    "\"bird\" = 2 \n",
    "\"cat\" = 3 \n",
    "\"deer\" = 4 \n",
    "\"dog\" = 5 \n",
    "\"frog\" = 6 \n",
    "\"horse\" = 7 \n",
    "\"ship\" = 8 \n",
    "\"truck\" = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58da29",
   "metadata": {},
   "source": [
    "# Create a function to display the Images and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60946bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(x, y, index):\n",
    "    plt.figure(figsize = (15, 2))\n",
    "    plt.imshow(x[index])\n",
    "    plt.xlabel(y_classes[y[index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f0ea5",
   "metadata": {},
   "source": [
    "# Test Prediction Accuray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7a12f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select any index from y_predictions to display the classification index \n",
    "y_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad7eb5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show image for selected y_predictions index\n",
    "showImage(X_test, y_test, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be3e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
